#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Mar 10 15:30:13 2021

@author: avinash
"""

import numpy as np
#mport random
#import time


################################
def leakyrelu(input, deriv = False):
    if deriv == True:
        return input * np.where(input>0, input, 0.01)
    return np.where(input>0,input, input*0.01)


def sigmoid(input, deriv=False):
    output = 1/(1+np.exp(-input)) 
    if deriv == True:
        return input * output*(1-output)
    return output 

   
def cross_entropy(output, target, deriv = False):
    m=target.shape[0]
    epsilon = 1e-5   
    if deriv == True:
        #return (np.subtract(output,target))*1/m
        return (1/m) * (-(target/output) + ((1-target)/(1-output)))
    return np.squeeze(-(1/m)*(np.sum(np.dot(np.log(output+epsilon),target.T) + np.dot(np.log(1-output+epsilon),(1-target).T))))
################################
    
#Random Initializaion
iarray  = np.random.rand(1,5) #Randomly Initalized Input Array
weight1 = np.random.rand(5,2) #Randomly Initalized weights for input neurons
bias1   = np.random.rand(1,2) #Randomly Initalized bias for input neurons
weight2 = np.random.rand(2,5) #Randomly Initalized wights for hidden neurons
bias2   = np.random.rand(1,5) #Randomly Initalized bias for hidden neurons

print('The Input array is: ',str(iarray))

#The target matrix we need is
target =np.array([[.12,.23,.36,.45,.59]])

print('The Target array is: ',str(target))

for i in range (3000000):
    
    #Begin forward propagation steps    
    
    #Multiply Input and Weight1 vectors, apply leakyrelu function
    hidden = leakyrelu(np.dot(iarray, weight1) +bias1)
                          
    #Muiltiply Hidden and Weight 2 vectors, apply sigmoid function
    output = sigmoid(np.dot(hidden,weight2) +bias2)
    
    #Calculate the total error using cross entropy log loss
    error = cross_entropy(output, target)
    print(' The cross entropy loss or total error is   :', str(error)) #<<- Uncomment this line to visualize error reduction at every iteration  
    
    # Implement backward propagation for gradient descent     
    
    #derivative of logistic classification with cross entropy [Target --> Output]
    #https://peterroelants.github.io/posts/cross-entropy-logistic/
    output_delta = cross_entropy(output, target, deriv=True)
    
    #derivative of sigmoid function on the output layer [Output --> Hidden]
    #http://www.ai.mit.edu/courses/6.892/lecture8-html/sld015.htm
    hidden_delta = sigmoid(output_delta, deriv=True)
    
    #derivative of the leakyrelu function on the hidden layer [Hidden --> Input]
    
    input_delta =  leakyrelu(hidden_delta, deriv= True)

    #Update weights with a learning rate of "0.5"
    weight2  -= 0.0008*hidden_delta
    weight1  -= 0.0008*input_delta.T
    
    #time.sleep(0.3)

print('The output array is: ',str(output))
print('The final error is :',str(error))
